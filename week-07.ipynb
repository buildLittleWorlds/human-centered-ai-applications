{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAH 30503 \u2014 Week 7: Responsible AI Hardening\n",
    "\n",
    "**Theme**: From \"it works\" to \"it's safe to use \u2014 and I can explain why.\"\n",
    "\n",
    "---\n",
    "\n",
    "Three activities today. First: **systematically catalog everything that could go wrong** with your app \u2014 technical failures, social failures, domain failures. Second: **ask whether this app should exist** using five hard questions. Third: **build safeguards** (input checks, output constraints, honest documentation) and **deploy v2**.\n",
    "\n",
    "This is the hardest session of the course. Not technically \u2014 you already know how to build and deploy. Hard because we\u2019re asking questions that challenge what you\u2019ve built. But you\u2019re asking these questions AFTER building, not before \u2014 which means you can answer with evidence, not speculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Starting Point\n",
    "\n",
    "Before we begin, confirm what you\u2019re working with:\n",
    "\n",
    "- **My app name**: \n",
    "\n",
    "- **My public URL**: \n",
    "\n",
    "- **Is it loading right now?** *(Visit the URL \u2014 free-tier Spaces sleep after inactivity.)*\n",
    "\n",
    "Pull up your Week 6 CLAUDE.md entry. You\u2019ll need:\n",
    "\n",
    "- **My #1 priority fix from Week 6**: \n",
    "\n",
    "- **My accountability statement**: When my ___ produces ___ in ___, ___ is most responsible because ___.\n",
    "\n",
    "- **My domain stakes**: Probability of error [L/M/H], Severity [L/M/H], Supervision level: ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Activity 1: Failure Mode Catalog\n",
    "\n",
    "Your user test found some problems. But what COULD go wrong that nobody has found yet?\n",
    "\n",
    "Every AI system can fail in three ways:\n",
    "\n",
    "| Category | What It Means | Examples |\n",
    "|----------|--------------|----------|\n",
    "| **Technical** | The system breaks or gives wrong answers | Wrong output, unexpected input, crashes, too slow |\n",
    "| **Social** | The system works but hurts people | Bias, privacy violation, misleading output, accessibility gaps |\n",
    "| **Domain** | The system works technically but the field rejects it | Inaccurate for the domain, doesn\u2019t fit the workflow, erodes trust |\n",
    "\n",
    "Technical failures are the easiest to find. Social failures are harder \u2014 they\u2019re about who gets helped and who gets hurt. Domain failures are the hardest \u2014 they require understanding the field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Failures\n",
    "\n",
    "For each type, think about YOUR app specifically.\n",
    "\n",
    "**Wrong output** \u2014 When could your model produce an incorrect result?\n",
    "- Specific example: \n",
    "- How likely is this? (Low / Medium / High): \n",
    "\n",
    "**Unexpected input** \u2014 What kind of input would your model NOT be trained on?\n",
    "- Specific example: \n",
    "- What happens if someone submits this? \n",
    "\n",
    "**Performance degradation** \u2014 Does your app work better on some inputs than others?\n",
    "- Works well on: \n",
    "- Works poorly on: \n",
    "\n",
    "**Cascading errors** \u2014 If one part of your pipeline gets it wrong, does the error get worse downstream?\n",
    "- Example: \n",
    "\n",
    "**Resource failures** \u2014 Could your app be too slow, crash, or run out of memory?\n",
    "- Most likely resource issue: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Failures\n",
    "\n",
    "Your app works. But who does it work FOR \u2014 and who does it work AGAINST?\n",
    "\n",
    "**Bias** \u2014 Does your model treat everyone fairly?\n",
    "- Who might be underrepresented in the training data? \n",
    "- Specific example of unfair treatment: \n",
    "\n",
    "**Privacy** \u2014 Could your app expose information that should stay private?\n",
    "- What goes into your app? Could it contain sensitive information? \n",
    "- What does your app output? Could the output reveal something private? \n",
    "\n",
    "**Manipulation** \u2014 Could your output mislead users, even unintentionally?\n",
    "- Example of misleading output: \n",
    "\n",
    "**Displacement** \u2014 Is your app replacing human judgment where it shouldn\u2019t be?\n",
    "- What human judgment does it replace? \n",
    "- Is that replacement appropriate? \n",
    "\n",
    "**Accessibility** \u2014 Who can\u2019t use your app?\n",
    "- Users who would be excluded: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Failures\n",
    "\n",
    "Your app works technically \u2014 but would an expert in the field trust it?\n",
    "\n",
    "**Domain inaccuracy** \u2014 What would a practitioner reject?\n",
    "- Example of output an expert wouldn\u2019t accept: \n",
    "\n",
    "**Workflow disruption** \u2014 Does your app fit how people actually work?\n",
    "- How people currently do this task: \n",
    "- Where my app fits (or doesn\u2019t): \n",
    "\n",
    "**Trust violation** \u2014 Could your app erode trust in AI for this domain?\n",
    "- If this app gave wrong output to [user], they might stop trusting: \n",
    "\n",
    "**Accountability gap** \u2014 Is anyone positioned to catch the error?\n",
    "- Who reviews the output before someone acts on it? \n",
    "- If nobody: that\u2019s a gap.\n",
    "\n",
    "**Stakes mismatch** \u2014 Does the supervision match the consequences?\n",
    "- Consequences of wrong output: \n",
    "- Current supervision level: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure Assessment Grid\n",
    "\n",
    "Pick your **top 5 failure modes** from all three categories. Rate each one.\n",
    "\n",
    "**Priority guide:**\n",
    "- **P1** (must address): High severity regardless of probability, OR high probability with medium+ severity\n",
    "- **P2** (should address): Medium severity with medium probability, OR high probability with low severity\n",
    "- **P3** (monitor): Low severity with low probability\n",
    "\n",
    "| # | Failure Mode | Category | Probability | Severity | Priority |\n",
    "|---|---|---|---|---|---|\n",
    "| 1 | | Tech / Social / Domain | Low / Med / High | Low / Med / High | P1 / P2 / P3 |\n",
    "| 2 | | | | | |\n",
    "| 3 | | | | | |\n",
    "| 4 | | | | | |\n",
    "| 5 | | | | | |\n",
    "\n",
    "**How many of your top 5 are technical vs. social vs. domain?** \n",
    "\n",
    "**What does that distribution tell you?** \n",
    "\n",
    "You don\u2019t have to fix everything. But you have to NAME everything. P3 failures that you\u2019ve named and decided to monitor are responsible. Failures you never identified are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Activity 2: Should We Build This?\n",
    "\n",
    "Everything in this course has been about building. Now we ask a question the course has never asked directly: **should this app exist?**\n",
    "\n",
    "Not \"can you build it\" \u2014 you can. Not \"will it work\" \u2014 you\u2019ve tested it. The question is: **should it exist?**\n",
    "\n",
    "Five questions. Answer them in order, using your failure catalog as evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: What problem am I solving?\n",
    "\n",
    "Not \"what can my AI do?\" but \"what problem does a real person have?\"\n",
    "\n",
    "**Red flags**: \"I\u2019m building this because AI can do it\" (technology push). \"I\u2019m building this because it\u2019s cool\" (impressive \u2260 responsible).\n",
    "\n",
    "**Green flags**: \"A [specific person] spends [time] doing [task] and it\u2019s [painful/slow/error-prone].\"\n",
    "\n",
    "- **The problem I\u2019m solving**: \n",
    "\n",
    "- **Who has this problem**: \n",
    "\n",
    "- **Why it matters (without mentioning AI)**: \n",
    "\n",
    "- **Red flag check**: Is this technology push or problem pull? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What happens when it\u2019s wrong?\n",
    "\n",
    "Use your Failure Mode Catalog as evidence.\n",
    "\n",
    "| Severity Level | What It Means |\n",
    "|---|---|\n",
    "| Annoyance | User has to redo something |\n",
    "| Wasted time | User loses hours of work |\n",
    "| Financial harm | User loses money |\n",
    "| Reputation harm | Someone\u2019s reputation is damaged |\n",
    "| Physical harm | Someone\u2019s health or safety is affected |\n",
    "| Systemic harm | A pattern of errors affects an entire community |\n",
    "\n",
    "- **Most likely error** (from your failure catalog): \n",
    "  - Severity level: \n",
    "  - How often: \n",
    "\n",
    "- **Most severe error** (from your failure catalog): \n",
    "  - Severity level: \n",
    "  - How often: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Could a simpler approach work?\n",
    "\n",
    "**The Simpler Alternative Test**: Describe what your app does WITHOUT using the words \"AI,\" \"model,\" \"neural network,\" or \"machine learning.\"\n",
    "\n",
    "**My app\u2019s function in plain language**: \n",
    "\n",
    "\n",
    "\n",
    "Now \u2014 could you build THAT with simpler tools?\n",
    "\n",
    "| Simpler Alternative | Could it work? | What would you lose? |\n",
    "|---|---|---|\n",
    "| A checklist | | |\n",
    "| A lookup table | | |\n",
    "| A set of if/then rules | | |\n",
    "| A template with variables | | |\n",
    "| A human doing it manually | | |\n",
    "\n",
    "**What specifically requires AI that none of these can handle?**\n",
    "\n",
    "\n",
    "\n",
    "AI adds value when the task requires pattern recognition across variable inputs. If the task is predictable, structured, or rule-based, simpler tools are more reliable, more transparent, and easier to audit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Who bears the risk?\n",
    "\n",
    "The person who builds the system rarely bears the full risk of its failures.\n",
    "\n",
    "- **Who uses the output?** \n",
    "\n",
    "- **Who makes decisions based on it?** \n",
    "\n",
    "- **Who is affected by those decisions?** \n",
    "\n",
    "- **Did those people choose to use AI?** \n",
    "\n",
    "- **Power check**: Are the people bearing the most risk the ones with the least power? \n",
    "\n",
    "### Question 5: Can I explain this to a skeptic?\n",
    "\n",
    "Not to a friendly audience. To someone who asks hard questions.\n",
    "\n",
    "- \"Why did you use AI instead of [alternative]?\" \n",
    "\n",
    "- \"What could go wrong?\" \n",
    "\n",
    "- \"Who is responsible when it fails?\" \n",
    "\n",
    "- \"How do you know it\u2019s not biased?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Verdict\n",
    "\n",
    "Based on your answers to all 5 questions:\n",
    "\n",
    "**Option A: Build with safeguards** \u2014 Real problem. AI adds genuine value. Risks are manageable.\n",
    "- Safeguards needed: \n",
    "\n",
    "**Option B: Simplify** \u2014 Core function needs AI, but some components should use simpler tools.\n",
    "- What to simplify: \n",
    "\n",
    "**Option C: Don\u2019t build (or significantly reconceive)** \u2014 Risks outweigh benefits.\n",
    "- Why: \n",
    "\n",
    "---\n",
    "\n",
    "**I choose Option**: A / B / C\n",
    "\n",
    "**My reasoning** (reference your answers above): \n",
    "\n",
    "\n",
    "\n",
    "**What I would tell the skeptic**: \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "*Share your verdict with a partner. They play the skeptic for 2 minutes: \"Convince me this should exist.\"*\n",
    "\n",
    "**My partner\u2019s toughest question**: \n",
    "\n",
    "**My response**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Activity 3: Build Safeguards\n",
    "\n",
    "Three types of protection. You need at least one of each.\n",
    "\n",
    "### Input Safeguards \u2014 Catch problems BEFORE the model runs\n",
    "\n",
    "| Safeguard | What It Catches | Implementation |\n",
    "|---|---|---|\n",
    "| Empty input check | User submits nothing | `if not text.strip(): return \"Please provide some text.\"` |\n",
    "| Length limit | Input exceeds model capacity | `if len(text) > 5000: text = text[:5000]` + warning |\n",
    "| Format validation | Wrong input type | Check type/format before model call |\n",
    "| Scope check | Input outside system\u2019s domain | Keyword detection or pattern matching |\n",
    "\n",
    "### Output Safeguards \u2014 Limit harm AFTER the model runs\n",
    "\n",
    "| Safeguard | What It Catches | Implementation |\n",
    "|---|---|---|\n",
    "| Confidence threshold | Low-confidence predictions | `if score < 0.7: flag as uncertain` |\n",
    "| Output disclaimer | All outputs | Append \"AI-generated \u2014 verify before acting\" |\n",
    "| Range checking | Out-of-bounds values | `if result > MAX: flag` |\n",
    "| Length constraint | Unexpectedly long output | Truncate and note truncation |\n",
    "\n",
    "### Documentation Safeguards \u2014 Tell users the truth\n",
    "\n",
    "This is your **Capability Statement** \u2014 what your app does well, what it gets wrong, and what it shouldn\u2019t be used for.\n",
    "\n",
    "---\n",
    "\n",
    "**Safeguard theater** is protection that LOOKS good but doesn\u2019t actually change what happens when the system fails. A disclaimer nobody reads is theater. Input validation that catches the most common failure-causing inputs is real.\n",
    "\n",
    "If a safeguard doesn\u2019t change what happens when the system fails, it\u2019s theater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q transformers torch gradio\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"Setup complete.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Your Input Safeguard\n",
    "\n",
    "Which P1/P2 failure mode does this address? \n",
    "\n",
    "What should happen when bad input arrives? "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DEMO: Input validation function\n",
    "# This catches common failure-causing inputs BEFORE the model runs.\n",
    "\n",
    "def validate_input(text):\n",
    "    \"\"\"Check input before sending to the model.\"\"\"\n",
    "    # Guard 1: Empty input\n",
    "    if not text or not text.strip():\n",
    "        return False, \"Please provide some text to analyze.\"\n",
    "\n",
    "    # Guard 2: Too short for reliable analysis\n",
    "    if len(text.split()) < 3:\n",
    "        return False, \"Input is too short for reliable analysis. Please provide at least a sentence.\"\n",
    "\n",
    "    # Guard 3: Too long (exceeds model capacity)\n",
    "    if len(text) > 5000:\n",
    "        return False, f\"Input is too long ({len(text)} characters). Please keep it under 5,000.\"\n",
    "\n",
    "    return True, \"Input valid\"\n",
    "\n",
    "\n",
    "# Test it\n",
    "test_inputs = [\"\", \"  \", \"hi\", \"This is a normal input for analysis.\", \"x \" * 3000]\n",
    "for inp in test_inputs:\n",
    "    valid, message = validate_input(inp)\n",
    "    display = repr(inp[:40])\n",
    "    print(f\"Input: {display:<45} Valid: {valid}  Message: {message}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# YOUR INPUT SAFEGUARD\n",
    "# Adapt the pattern above for YOUR app and YOUR P1/P2 findings.\n",
    "#\n",
    "# def validate_input(text):\n",
    "#     # What checks does YOUR app need?\n",
    "#     # - Empty input?\n",
    "#     # - Too short / too long?\n",
    "#     # - Wrong language?\n",
    "#     # - Out of scope for your domain?\n",
    "#     pass\n",
    "#\n",
    "# Test with inputs that SHOULD be caught and inputs that SHOULD pass:\n",
    "\n",
    "print(\"Uncomment and adapt the code above for YOUR app.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My input safeguard**:\n",
    "- What it checks for: \n",
    "- Which failure mode it addresses: \n",
    "- What happens when it catches bad input: \n",
    "- What it does NOT catch (honest limitation): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Your Output Safeguard\n",
    "\n",
    "Which P1/P2 failure mode does this address? \n",
    "\n",
    "What should the user see when the model is uncertain? "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DEMO: Output safeguard function\n",
    "# This checks the model's output BEFORE showing it to the user.\n",
    "\n",
    "def safeguard_output(result, confidence_threshold=0.7):\n",
    "    \"\"\"Apply safeguards to model output before returning to user.\"\"\"\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "\n",
    "    # Safeguard 1: Low confidence warning\n",
    "    if score < confidence_threshold:\n",
    "        disclaimer = f\"\\u26a0\\ufe0f Low confidence ({score:.0%}). This result may not be reliable.\"\n",
    "    else:\n",
    "        disclaimer = f\"Confidence: {score:.0%}\"\n",
    "\n",
    "    # Safeguard 2: General disclosure\n",
    "    disclosure = \"Note: This is AI-generated analysis. Verify important results independently.\"\n",
    "\n",
    "    return f\"{label} \\u2014 {disclaimer}\\n{disclosure}\"\n",
    "\n",
    "\n",
    "# Test it with a real model\n",
    "classifier = pipeline(\"sentiment-analysis\", device=device)\n",
    "\n",
    "test_texts = [\"I love this product!\", \"meh\", \"asdfghjkl\", \"The weather is okay I guess.\"]\n",
    "for text in test_texts:\n",
    "    raw = classifier(text)[0]\n",
    "    safe = safeguard_output(raw)\n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"  Raw: {raw['label']} ({raw['score']:.3f})\")\n",
    "    print(f\"  Safe: {safe}\")\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# YOUR OUTPUT SAFEGUARD\n",
    "# Adapt the pattern above for YOUR app and YOUR P1/P2 findings.\n",
    "#\n",
    "# def safeguard_output(result):\n",
    "#     # What checks does YOUR output need?\n",
    "#     # - Confidence threshold?\n",
    "#     # - Range checking?\n",
    "#     # - Disclaimer for certain output types?\n",
    "#     # - Truncation for unexpectedly long output?\n",
    "#     pass\n",
    "#\n",
    "# Test with outputs that SHOULD trigger safeguards and outputs that SHOULD pass:\n",
    "\n",
    "print(\"Uncomment and adapt the code above for YOUR app.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My output safeguard**:\n",
    "- What it checks for: \n",
    "- Which failure mode it addresses: \n",
    "- What the user sees when it triggers: \n",
    "- What it does NOT catch (honest limitation): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Your Capability Statement\n",
    "\n",
    "This isn\u2019t a disclaimer. It\u2019s a feature. Users who know what to expect trust the product more than users who were promised magic.\n",
    "\n",
    "Draw on: your Week 6 user testing findings, your failure catalog from Activity 1, your Should-We-Build-This analysis from Activity 2.\n",
    "\n",
    "---\n",
    "\n",
    "**What This Product Does**:\n",
    "\n",
    "*(Clear, specific description \u2014 not marketing language)*\n",
    "\n",
    "\n",
    "\n",
    "**What It Does Well**:\n",
    "\n",
    "*(Specific strengths, with examples. Not \"analyzes text\" but \"identifies sentiment with high accuracy for formal English product reviews.\")*\n",
    "\n",
    "\n",
    "\n",
    "**What It Sometimes Gets Wrong**:\n",
    "\n",
    "*(Specific failure modes users should know about. Not \"may produce errors\" but \"struggles with sarcasm and non-English text.\")*\n",
    "\n",
    "\n",
    "\n",
    "**What It Should NOT Be Used For**:\n",
    "\n",
    "*(Clear boundaries. Not \"use responsibly\" but \"do not use for medical, legal, or financial decisions.\")*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safeguard Check\n",
    "\n",
    "Before deploying, check your safeguards against the \"theater\" test:\n",
    "\n",
    "- [ ] My input safeguard **changes what happens** when bad input arrives (not just logs it)\n",
    "- [ ] My output safeguard **changes what the user sees** when the model is uncertain (not just adds fine print)\n",
    "- [ ] My Capability Statement is **specific enough** that a user could decide whether to trust the output\n",
    "- [ ] If a failure still gets through my safeguards, **the harm is reduced** compared to no safeguards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Activity 4: Deploy v2\n",
    "\n",
    "Push your safeguards and Capability Statement to your HF Space.\n",
    "\n",
    "### What to Update\n",
    "\n",
    "1. **`app.py`**: Add your input validation and output safeguards to your function(s)\n",
    "2. **Capability Statement**: Add as `gr.Markdown()` in your Gradio interface, or update your Space description\n",
    "3. **Push to HF Space**: Same process as Week 5 \u2014 upload updated files\n",
    "4. **Verify**: Visit your URL. Test with empty input. Test with a normal input. Check that the Capability Statement is visible.\n",
    "\n",
    "### Quick Integration Pattern\n",
    "\n",
    "```python\n",
    "# Add to the top of your Gradio app:\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# My App Title\")\n",
    "    gr.Markdown(\"\"\"**What this does well**: [specific strengths]\n",
    "    \n",
    "**Known limitations**: [specific limitations]\n",
    "    \n",
    "**Not for**: [specific boundaries]\"\"\")\n",
    "    \n",
    "    # ... rest of your interface ...\n",
    "```\n",
    "\n",
    "Or use Claude Code: *\"Add my Capability Statement as a visible section at the top of my Gradio app, and add input validation that returns a helpful message for empty input.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2 Verification\n",
    "\n",
    "- **My v2 URL** *(same URL, updated app)*: \n",
    "\n",
    "- **Is the Capability Statement visible?** \n",
    "\n",
    "- **Does the input safeguard work?** *(Try empty input.)* \n",
    "\n",
    "- **Does the output safeguard work?** *(Try an input that should trigger low confidence.)* \n",
    "\n",
    "- **Partner check** \u2014 send your URL to a classmate:\n",
    "  - Can they see the Capability Statement? \n",
    "  - Do the safeguards work for them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6-Question Examination Protocol\n",
    "\n",
    "Apply the protocol to this week\u2019s entire process \u2014 failure cataloging, should-we-build-this, safeguard building, and deployment.\n",
    "\n",
    "### 1. What did I set out to do?\n",
    "*(Systematically find what could go wrong, decide if my app should exist, build protections, deploy v2.)*\n",
    "\n",
    "\n",
    "### 2. What did I actually find?\n",
    "*(How many failure modes? What was the Should-We-Build-This verdict? What safeguards did I build?)*\n",
    "\n",
    "\n",
    "### 3. Where did the process succeed?\n",
    "*(Which examinations revealed something I didn\u2019t know? Which safeguards address real failures?)*\n",
    "\n",
    "\n",
    "### 4. Where did the process fall short?\n",
    "*(Which failure categories were hardest? What safeguards feel like theater? What questions couldn\u2019t I answer?)*\n",
    "\n",
    "\n",
    "### 5. Why were some parts harder than others?\n",
    "*(Was naming social failures harder than technical? Was the Simpler Alternative Test uncomfortable?)*\n",
    "\n",
    "\n",
    "### 6. What would I do differently if starting this project today?\n",
    "*(Knowing what the failure catalog and Should-We-Build-This revealed \u2014 what would you build differently from Week 4?)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DCS Question: What Does Responsible Participation Look Like for This System?\n",
    "\n",
    "You\u2019ve been answering DCS questions all semester:\n",
    "- Week 1: What kind of system is this?\n",
    "- Week 2: What cognitive work gets outsourced?\n",
    "- Week 3: What knowledge is encoded in the models?\n",
    "- Week 4: Who directs this system?\n",
    "- Week 5: What connects this system to its users?\n",
    "- Week 6: Where does accountability live when this system is wrong?\n",
    "\n",
    "This week\u2019s question is different. It\u2019s not analytical \u2014 it\u2019s prescriptive: **given everything you know, what does it look like to participate responsibly in this cognitive system?**\n",
    "\n",
    "---\n",
    "\n",
    "Responsible participation in MY system means:\n",
    "\n",
    "- Naming ___ failure modes \u2014 including: \n",
    "\n",
    "- Asking whether ___ could replace ___ (from the Simpler Alternative Test): \n",
    "\n",
    "- Building ___ (safeguard) that catches ___ (failure mode) before users see it: \n",
    "\n",
    "- Telling users honestly that ___ (from Capability Statement): \n",
    "\n",
    "- Deciding that ___ supervision level is appropriate because ___ (from Week 6): \n",
    "\n",
    "---\n",
    "\n",
    "Responsible participation is NOT just having a disclaimer. It\u2019s: \n",
    "\n",
    "\n",
    "\n",
    "**Connect to a previous DCS answer**: How does this week\u2019s answer build on what you wrote in Week 5 or Week 6?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Record: CLAUDE.md Week 7 Entry\n",
    "\n",
    "Add this to your CLAUDE.md file:\n",
    "\n",
    "```\n",
    "## Week 7: Responsible AI Hardening\n",
    "\n",
    "### Failure Mode Catalog\n",
    "- Technical failures: [count and top examples]\n",
    "- Social failures: [count and top examples]\n",
    "- Domain failures: [count and top examples]\n",
    "\n",
    "### Top Priority Failures\n",
    "- P1 (must address): [list]\n",
    "- P2 (should address): [list]\n",
    "- P3 (monitor): [list]\n",
    "\n",
    "### Should-We-Build-This Assessment\n",
    "- Q1 (Problem): [real problem? who has it?]\n",
    "- Q2 (Wrong): [worst consequence \u2014 severity level]\n",
    "- Q3 (Simpler): [what could be simpler? what genuinely needs AI?]\n",
    "- Q4 (Risk): [who bears it? fair?]\n",
    "- Q5 (Skeptic): [can I defend this?]\n",
    "- Verdict: Build with safeguards / Simplify / Don't build\n",
    "- Reasoning: [key evidence]\n",
    "\n",
    "### Safeguards Implemented\n",
    "- Input safeguard: [what it checks, what it catches]\n",
    "- Output safeguard: [what it flags or constrains]\n",
    "- Capability Statement: [summary \u2014 does well / gets wrong / not for]\n",
    "\n",
    "### v2 Deployment\n",
    "- URL: [same or updated URL]\n",
    "- What changed from v1: [safeguards added, Capability Statement visible]\n",
    "- Safeguards tested: [what I verified]\n",
    "\n",
    "### DCS: What Does Responsible Participation Look Like?\n",
    "[Specific actions taken \u2014 failure cataloging, simpler alternative test,\n",
    " safeguard building, honest capability communication.\n",
    " What does responsible participation mean for THIS system?]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What\u2019s Next\n",
    "\n",
    "You can defend what you built. You have a failure catalog, a Should-We-Build-This assessment, safeguards, and a Capability Statement.\n",
    "\n",
    "**Next week is the last session**: you ship and reflect. You\u2019ll polish your app, write a Product Brief, present to the class, and reflect on what the whole course taught you about building AI systems for real people. Bring everything \u2014 your CLAUDE.md, your deployed URL, your Capability Statement."
   ]
  }
 ]
}
